{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import collections\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "from nltk.corpus import words\n",
    "\n",
    "#plotly configuration\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_Traindata = []\n",
    "    processed_Testdata = []\n",
    "    wordlist = []\n",
    "    \n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    \n",
    "    def initialize(self, csv_file, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file, usecols=[0,1,5,10,15])\n",
    "        train, test = train_test_split(self.data, test_size=0.99)\n",
    "        self.processed_Traindata = train\n",
    "        self.processed_Testdata = test\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>5.678700e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir According to TV passenger interv...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>5.701010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir  your customer service is deplora...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.699070e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica - Let 2 scanned in passengers l...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>5.702550e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir strives to be 'Customer Centric'...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.697780e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and again! Another rep kicked b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13988</th>\n",
       "      <td>5.696810e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir I'm on #1058 tmrw from CUN DFW. F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>5.692480e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica can you please get me to the ne...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>5.678140e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united @gg8929 so why did you Cancelled Fligh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>5.687790e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue are there any food places open at the...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>5.684930e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united 777 from SFO to HNL with ZERO entertai...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>5.697150e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir wow that's helpful.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>5.702580e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways Thank you, although we're using our...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>5.695210e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Found flight after 2.5 hrs. How am I o...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>5.702720e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir we are off to Kax premium.  Hopin...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>5.691710e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united your website won't allow me to post th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>5.686060e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united after waiting for over an hour we fina...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>5.678560e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir @Imaginedragons when are we gonn...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>5.692560e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir I'm just calling to Cancelled Fl...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>5.689100e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways there is nothing tonight and I am o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>5.699390e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>@united thank YOU for your kindness. Your agen...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8809</th>\n",
       "      <td>5.678290e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue Still love you guys. But get me to Ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>5.680570e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways my vacation budget was blown bc of ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10808</th>\n",
       "      <td>5.688590e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways &amp;amp; also that I was told no comps...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11079</th>\n",
       "      <td>5.685280e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways tells me to talk to @AmericanAir ab...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12435</th>\n",
       "      <td>5.701880e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir especially during a death in the ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13591</th>\n",
       "      <td>5.698160e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir Your rubbish at Social Media! In ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>5.697010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Made@it to the gate at 8:23 and they w...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>5.679860e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Y do U not reply to customer refund fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>5.688050e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@jetblue when i sign in into TrueBlue, why do ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>5.702760e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir robocalls me with another Cancell...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9393</th>\n",
       "      <td>5.699560e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways delays due to refueling are out of ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11208</th>\n",
       "      <td>5.684320e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways I'm trying to merge my freq flyer a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>5.702090e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Done and done</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>5.692140e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Friend at O'Hare and can't get on flig...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>5.695120e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways And the lies continue. Just waited ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>5.694570e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways @AmericanAir Suggestions , been on ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>5.680820e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir @love_dragonss LAUREN IM SCREAKJMF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344</th>\n",
       "      <td>5.696590e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue that is a stock response. Delays not ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>5.691910e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue that I missed my flight. I had to boo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.699110e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica why is flight 345 redirected?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>5.700060e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir crew did the best they could but ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>5.687640e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@Southwestair is this account even aware of th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>5.691840e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways @shivadelrahim what about upgrades?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>5.677320e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir Got it, thanks. Any insight into...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11340</th>\n",
       "      <td>5.681940e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways Cant help but be frustrated after a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>5.688280e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united @44Stocker my wife Sarah stocker did a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>5.689450e+17</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica Grand Budapest Hotel #OscarsCou...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8609</th>\n",
       "      <td>5.681160e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue also. Emergency exit seats. 6'2\" and ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>5.695310e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united as if a 4 hour maintenance delay wasn'...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>5.692450e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue hopefully this flight Seattle to Bost...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>5.685060e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways not moving we are in the tarmac del...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>5.689740e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>@SouthwestAir flight to San Diego is delayed p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>5.687870e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Please send me the link/email to forma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>5.677300e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united's first-class #cockup\\nhttp://t.co/oh7...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>5.690000e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways It says to call. Before connecting,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12689</th>\n",
       "      <td>5.700610e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir You found my lost luggage, won't ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>5.678650e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@JetBlue received horrible customer service at...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>5.682690e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Trying to change a flight booked just ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14481</th>\n",
       "      <td>5.696090e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir appreciate update. Have also appr...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>5.678340e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>@united Why do I pay more for Coach Plus to be...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id airline_sentiment         airline  \\\n",
       "6420   5.678700e+17          negative       Southwest   \n",
       "12569  5.701010e+17          negative        American   \n",
       "97     5.699070e+17          negative  Virgin America   \n",
       "4439   5.702550e+17          positive       Southwest   \n",
       "117    5.697780e+17          positive  Virgin America   \n",
       "13988  5.696810e+17           neutral        American   \n",
       "207    5.692480e+17           neutral  Virgin America   \n",
       "4122   5.678140e+17          negative          United   \n",
       "8113   5.687790e+17           neutral           Delta   \n",
       "3367   5.684930e+17          negative          United   \n",
       "13800  5.697150e+17          positive        American   \n",
       "9064   5.702580e+17           neutral      US Airways   \n",
       "1918   5.695210e+17          negative          United   \n",
       "12165  5.702720e+17          positive        American   \n",
       "2487   5.691710e+17          negative          United   \n",
       "3192   5.686060e+17          negative          United   \n",
       "6445   5.678560e+17           neutral       Southwest   \n",
       "5215   5.692560e+17          negative       Southwest   \n",
       "10751  5.689100e+17           neutral      US Airways   \n",
       "1066   5.699390e+17          positive          United   \n",
       "8809   5.678290e+17          positive           Delta   \n",
       "11516  5.680570e+17          negative      US Airways   \n",
       "10808  5.688590e+17          negative      US Airways   \n",
       "11079  5.685280e+17          negative      US Airways   \n",
       "12435  5.701880e+17          negative        American   \n",
       "13591  5.698160e+17          negative        American   \n",
       "1487   5.697010e+17          negative          United   \n",
       "3913   5.679860e+17          negative          United   \n",
       "8083   5.688050e+17          negative           Delta   \n",
       "11982  5.702760e+17          negative        American   \n",
       "...             ...               ...             ...   \n",
       "9393   5.699560e+17          negative      US Airways   \n",
       "11208  5.684320e+17          negative      US Airways   \n",
       "669    5.702090e+17           neutral          United   \n",
       "2424   5.692140e+17          negative          United   \n",
       "10164  5.695120e+17          negative      US Airways   \n",
       "10252  5.694570e+17          negative      US Airways   \n",
       "6286   5.680820e+17           neutral       Southwest   \n",
       "7344   5.696590e+17          negative           Delta   \n",
       "7844   5.691910e+17          negative           Delta   \n",
       "94     5.699110e+17           neutral  Virgin America   \n",
       "12830  5.700060e+17          negative        American   \n",
       "5739   5.687640e+17          negative       Southwest   \n",
       "10559  5.691840e+17           neutral      US Airways   \n",
       "6692   5.677320e+17           neutral       Southwest   \n",
       "11340  5.681940e+17          negative      US Airways   \n",
       "2930   5.688280e+17          negative          United   \n",
       "260    5.689450e+17           neutral  Virgin America   \n",
       "8609   5.681160e+17          positive           Delta   \n",
       "1895   5.695310e+17          negative          United   \n",
       "7786   5.692450e+17          negative           Delta   \n",
       "11099  5.685060e+17          negative      US Airways   \n",
       "5461   5.689740e+17          negative       Southwest   \n",
       "3035   5.687870e+17          positive          United   \n",
       "4295   5.677300e+17          negative          United   \n",
       "10657  5.690000e+17          negative      US Airways   \n",
       "12689  5.700610e+17          negative        American   \n",
       "8763   5.678650e+17          negative           Delta   \n",
       "3559   5.682690e+17          negative          United   \n",
       "14481  5.696090e+17          positive        American   \n",
       "4076   5.678340e+17          negative          United   \n",
       "\n",
       "                                                    text  topic_label  \n",
       "6420   @SouthwestAir According to TV passenger interv...            6  \n",
       "12569  @AmericanAir  your customer service is deplora...            2  \n",
       "97     @VirginAmerica - Let 2 scanned in passengers l...            6  \n",
       "4439   @SouthwestAir strives to be 'Customer Centric'...            7  \n",
       "117    @VirginAmerica and again! Another rep kicked b...            2  \n",
       "13988  @AmericanAir I'm on #1058 tmrw from CUN DFW. F...            1  \n",
       "207    @VirginAmerica can you please get me to the ne...            4  \n",
       "4122   @united @gg8929 so why did you Cancelled Fligh...            2  \n",
       "8113   @JetBlue are there any food places open at the...            9  \n",
       "3367   @united 777 from SFO to HNL with ZERO entertai...            6  \n",
       "13800                   @AmericanAir wow that's helpful.            3  \n",
       "9064   @USAirways Thank you, although we're using our...            1  \n",
       "1918   @united Found flight after 2.5 hrs. How am I o...            4  \n",
       "12165  @AmericanAir we are off to Kax premium.  Hopin...            9  \n",
       "2487   @united your website won't allow me to post th...            1  \n",
       "3192   @united after waiting for over an hour we fina...            8  \n",
       "6445   @SouthwestAir @Imaginedragons when are we gonn...            6  \n",
       "5215   @SouthwestAir I'm just calling to Cancelled Fl...            8  \n",
       "10751  @USAirways there is nothing tonight and I am o...            0  \n",
       "1066   @united thank YOU for your kindness. Your agen...            6  \n",
       "8809   @JetBlue Still love you guys. But get me to Ve...            0  \n",
       "11516  @USAirways my vacation budget was blown bc of ...            9  \n",
       "10808  @USAirways &amp; also that I was told no comps...            4  \n",
       "11079  @USAirways tells me to talk to @AmericanAir ab...            4  \n",
       "12435  @AmericanAir especially during a death in the ...            6  \n",
       "13591  @AmericanAir Your rubbish at Social Media! In ...            8  \n",
       "1487   @united Made@it to the gate at 8:23 and they w...            8  \n",
       "3913   @united Y do U not reply to customer refund fo...            0  \n",
       "8083   @jetblue when i sign in into TrueBlue, why do ...            3  \n",
       "11982  @AmericanAir robocalls me with another Cancell...            8  \n",
       "...                                                  ...          ...  \n",
       "9393   @USAirways delays due to refueling are out of ...            2  \n",
       "11208  @USAirways I'm trying to merge my freq flyer a...            1  \n",
       "669                                @united Done and done            9  \n",
       "2424   @united Friend at O'Hare and can't get on flig...            6  \n",
       "10164  @USAirways And the lies continue. Just waited ...            4  \n",
       "10252  @USAirways @AmericanAir Suggestions , been on ...            8  \n",
       "6286    @SouthwestAir @love_dragonss LAUREN IM SCREAKJMF            5  \n",
       "7344   @JetBlue that is a stock response. Delays not ...            8  \n",
       "7844   @JetBlue that I missed my flight. I had to boo...            4  \n",
       "94          @VirginAmerica why is flight 345 redirected?            8  \n",
       "12830  @AmericanAir crew did the best they could but ...            9  \n",
       "5739   @Southwestair is this account even aware of th...            2  \n",
       "10559     @USAirways @shivadelrahim what about upgrades?            6  \n",
       "6692   @SouthwestAir Got it, thanks. Any insight into...            0  \n",
       "11340  @USAirways Cant help but be frustrated after a...            1  \n",
       "2930   @united @44Stocker my wife Sarah stocker did a...            2  \n",
       "260    @VirginAmerica Grand Budapest Hotel #OscarsCou...            8  \n",
       "8609   @JetBlue also. Emergency exit seats. 6'2\" and ...            4  \n",
       "1895   @united as if a 4 hour maintenance delay wasn'...            4  \n",
       "7786   @JetBlue hopefully this flight Seattle to Bost...            6  \n",
       "11099  @USAirways not moving we are in the tarmac del...            8  \n",
       "5461   @SouthwestAir flight to San Diego is delayed p...            4  \n",
       "3035   @united Please send me the link/email to forma...            0  \n",
       "4295   @united's first-class #cockup\\nhttp://t.co/oh7...            6  \n",
       "10657  @USAirways It says to call. Before connecting,...            8  \n",
       "12689  @AmericanAir You found my lost luggage, won't ...            4  \n",
       "8763   @JetBlue received horrible customer service at...            4  \n",
       "3559   @united Trying to change a flight booked just ...            1  \n",
       "14481  @AmericanAir appreciate update. Have also appr...            8  \n",
       "4076   @united Why do I pay more for Coach Plus to be...            6  \n",
       "\n",
       "[146 rows x 5 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"../data/Tweets.csv\")\n",
    "data.processed_Traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\harin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "nltk.download('words')\n",
    "word_dictionary = list(set(words.words()))\n",
    "\n",
    "for alphabet in \"bcdefghjklmnopqrstuvwxyzBCDEFGHJKLMNOPQRSTUVWXYZ\":\n",
    "    word_dictionary.remove(alphabet)\n",
    "class DataPreprocessing:\n",
    "    def iterate(self):\n",
    "        for preprocessingMethod in [self.replaceProcessedHashtags,\n",
    "                                   self.removeUrls,\n",
    "                                   self.removeUsernames,\n",
    "                                   self.removeElongatedWords,\n",
    "                                   self.removeNa,\n",
    "                                   self.replaceSlangWords,\n",
    "                                   self.removeSpecialChars,\n",
    "                                   self.removeNumbers]:\n",
    "            yield preprocessingMethod\n",
    "    \n",
    "    @staticmethod\n",
    "    def removeByRegex(tweets, regExp):\n",
    "        tweets.loc[:, \"text\"].replace(regExp, \"\", inplace=True)\n",
    "        return tweets\n",
    "    \n",
    "    def removeUrls(self, tweets):\n",
    "        return DataPreprocessing.removeByRegex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "    \n",
    "    def removeNa(self, tweets):\n",
    "        return tweets[tweets[\"text\"] != \"\"]\n",
    "    \n",
    "    def removeSpecialChars(self, tweets):\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\"\n",
    "                                                                    \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                    \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                    \"!\", \"?\", \".\", \"'\",\n",
    "                                                                    \"--\", \"---\",\"#\"]):\n",
    "            tweets.loc[:, \"text\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "    \n",
    "    def removeUsernames(self, tweets):\n",
    "        return DataPreprocessing.removeByRegex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "    \n",
    "    def removeElongatedWords(self, tweets):\n",
    "        return DataPreprocessing.removeByRegex(tweets, regex.compile(r\"(.)\\1+', r'\\1\\1\"))\n",
    "    \n",
    "    def removeNumbers(self, tweets):\n",
    "        #print(tweets)\n",
    "        return DataPreprocessing.removeByRegex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))\n",
    "    \n",
    "    def replaceSlangWords(self, tweets):\n",
    "        with open('../data/slang.txt') as file:\n",
    "            slang_map = dict(map(str.strip, line.partition('\\t')[::2])\n",
    "            for line in file if line.strip())\n",
    "            #print(tweets[\"text\"])\n",
    "            #print(\"-----------------------------------------END\")\n",
    "            for index,word in tweets['text'].iteritems():\n",
    "                #print(index)\n",
    "                for i in word.split():\n",
    "                    isUpperCase = i.isupper()\n",
    "                    i = i.lower()\n",
    "                    if i in slang_map.keys():\n",
    "                        word = word.replace(i, slang_map[i])\n",
    "                        tweets.loc[(index),\"text\"] = word\n",
    "                if isUpperCase:\n",
    "                    i = i.upper()\n",
    "        #print(tweets.loc[:,\"text\"])\n",
    "        return tweets\n",
    "\n",
    "    # print(split_tweets)\n",
    "    @staticmethod\n",
    "    def removeDigitsFromHashtag(tag):\n",
    "        tag = regex.sub(r\"\\s?[0-9]+\\.?[0-9]*\", \"\", tag)\n",
    "        return tag\n",
    "\n",
    "    @staticmethod\n",
    "    def collect_hashtags_in_tweet(wordList):\n",
    "        hashtags = []\n",
    "        for word in wordList:\n",
    "            index = word.find('#')\n",
    "            if index != -1:\n",
    "                if word[index + 1:] != '':\n",
    "                    hashtags.append(word[index + 1:])\n",
    "        return hashtags\n",
    "\n",
    "    @staticmethod\n",
    "    def split_hashtag_to_words_all_possibilities(hashtag):\n",
    "        all_possibilities = []\n",
    "\n",
    "        split_posibility = [hashtag[:i] in word_dictionary for i in reversed(range(len(hashtag) + 1))]\n",
    "        possible_split_positions = [i for i, x in enumerate(split_posibility) if x == True]\n",
    "\n",
    "        for split_pos in possible_split_positions:\n",
    "            split_words = []\n",
    "            word_1, word_2 = hashtag[:len(hashtag) - split_pos], hashtag[len(hashtag) - split_pos:]\n",
    "\n",
    "            if word_2 in word_dictionary:\n",
    "                split_words.append(word_1)\n",
    "                split_words.append(word_2)\n",
    "                all_possibilities.append(split_words)\n",
    "\n",
    "                another_round = DataPreprocessing.split_hashtag_to_words_all_possibilities(word_2)\n",
    "\n",
    "                if len(another_round) > 0:\n",
    "                    all_possibilities = all_possibilities + [[a1] + a2 for a1, a2, in\n",
    "                                                             zip([word_1] * len(another_round), another_round)]\n",
    "            else:\n",
    "                another_round = DataPreprocessing.split_hashtag_to_words_all_possibilities(word_2)\n",
    "\n",
    "                if len(another_round) > 0:\n",
    "                    all_possibilities = all_possibilities + [[a1] + a2 for a1, a2, in\n",
    "                                                             zip([word_1] * len(another_round), another_round)]\n",
    "\n",
    "        return all_possibilities\n",
    "\n",
    "    @staticmethod\n",
    "    def process_all_hashtags_in_tweet(hashtags):\n",
    "        all_words = []\n",
    "        for tag in hashtags:\n",
    "            split_hashtag = DataPreprocessing.split_hashtag_to_words_all_possibilities(DataPreprocessing.removeDigitsFromHashtag(tag))\n",
    "            if split_hashtag:\n",
    "                all_words = all_words + split_hashtag[0]\n",
    "            else:\n",
    "                all_words.append(tag)\n",
    "        return all_words \n",
    "    \n",
    "    def replaceProcessedHashtags(self, tweets):\n",
    "            for index,word in tweets['text'].iteritems():\n",
    "                word=word.split()\n",
    "                collectHashtags=DataPreprocessing.collect_hashtags_in_tweet(word)\n",
    "                allHashtags=DataPreprocessing.process_all_hashtags_in_tweet(collectHashtags)\n",
    "                collectHashtags = [\"#\" + tag for tag in collectHashtags]\n",
    "                if allHashtags:\n",
    "                    word = list(set(word) - set(collectHashtags))\n",
    "                    word = word + allHashtags\n",
    "                word = \" \".join(word)\n",
    "                tweets.loc[(index),\"text\"] = word\n",
    "                print(tweets.loc[(index),\"text\"])\n",
    "           # print(tweets)\n",
    "            return tweets\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Training Data\n",
    "class CleanTrainingData(TwitterData_Initialize):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_Traindata = previous.processed_Traindata\n",
    "        #self.processed_Testdata = previous.processed_Testdata\n",
    "    \n",
    "    def cleaningData(self, cleaner):\n",
    "        train = self.processed_Traindata\n",
    "        #test = self.processed_Testdata\n",
    "        for cleanerMethod in cleaner.iterate():\n",
    "            train = cleanerMethod(train)\n",
    "            #test = cleanerMethod(test)\n",
    "        self.processed_Traindata = train\n",
    "        #self.processed_Testdata = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SouthwestAir According to TV passenger interviews, the landing was far from \"uneventful\" with heavy (panic) breaking to\n",
      "@AmericanAir your customer service is deplorable. I am disgusted in your company and the ignorant people on the phones for lost baggage.\n",
      "remove bag 2 the from scanned leave @VirginAmerica class plane bin? someone told their in 1st - passengers to than Let uncomfort able\n",
      "@SouthwestAir they advertising, 'Customer etc. do journey, in customer - to be communications, Centric' strives everything ANAmarketers\n",
      "@VirginAmerica and again! Another rep kicked butt! Naelah represents your team so beautifully!! Thank you!!!\n",
      "morning. CUN rain Should on from dest'n I DFW. ORD. Final is in DFW freezing all Seeing tmrw @AmericanAir connection? I'm my change 1058\n",
      "@VirginAmerica can you please get me to the new york area before monday afternoon\n",
      "when Cancelled the people @united didn't rate? tickets you Flight thousands of like for @gg8929 so did why exchange doublestandards\n",
      "@JetBlue are there any food places open at the JFK T5 24//?\n",
      "@united to from 777 HNL systems???!!!#youareonyourown with entertainment ZERO SFO you are on your own\n",
      "@AmericanAir wow that's helpful.\n",
      "@USAirways Thank you, although we're using our miles from our card and Flight Booking Problems companion tickets which can only be booked over the phone.\n",
      "@united Found flight after 2.5 hrs. How am I offered a $200 flight voucher 12 hrs before, lose my seat out of neglect, then get nothing?\n",
      "@AmericanAir we are off to Kax premium. Hoping this flight is better food, TV now I know how to work it and service. Tnx\n",
      "@united your website won't allow me to post the required document, i keep getting **were having technical difficulties**\n",
      "@united after waiting for over an hour we finally board the airplane only to find out we have to call maintenance. And this plane is cold.üò°\n",
      "can't when are @SouthwestAir concentrateüò≠üò≠ test a we math I tomoro know have gonna and @Imaginedragons DestinationDragons\n",
      "@SouthwestAir I'm just calling to Cancelled Flight a flight. I already rebooked it on another card. Just need to Cancelled Flight the previous reservation.\n",
      "@USAirways there is nothing tonight and I am on the flight now with GOGO internet is there a way that someone could send me a DM or email?\n",
      "@united thank YOU for your kindness. Your agents went above &amp; beyond to get my stranded family home.\n",
      "@JetBlue Still love you guys. But get me to Vegas already! ‚òÄÔ∏èüå¥‚úàÔ∏èüç∏üé≤\n",
      "@USAirways my vacation budget was blown bc of the lack of communication from USAirways. I will never use them again or refer anyone!\n",
      "was @USAirways &amp; that ReFlight enough. good etc. I Booking no also told is upgrades, comps, Problems us air ways fail\n",
      "flights. tells me about US. @USAirways delayed AA to @AmericanAir my talk i hat em erg ers\n",
      "@AmericanAir especially during a death in the family and still no solution. 96 hours and counting...Thanks\n",
      "@AmericanAir Your rubbish at Social Media! In the air two hours Late Flight but that's better than being Cancelled Flightled!\n",
      "@united Made@it to the gate at 8:23 and they wouldn't let us on. http://t.co/xAToxBnsFa\n",
      "refund forms??????????? not U customer @united to reply do Y united air lin es\n",
      "@jetblue when i sign in into TrueBlue, why do I have to do it twice? happens to everyone around me\n",
      "@AmericanAir robocalls me with another Cancelled Flightation. And then when I don‚Äôt accept the change it won‚Äôt let me connect to an agent. Just wow.\n",
      "@united need assistance. Line is out the door and travelling with 3 kids.\n",
      "‚Äú@AmericanAir: \"Jason, you'll end up missing your connection. Please see our DFW agents for assistance.‚Äù Nope! Hasn't taken off yet, still!\n",
      "@JetBlue many thanks, as always your employees are professional and courteous. Whenever I have the option, you are my go-to airlines.\n",
      "@united Fantastic job by your people today on ua22 from Dublin. A jam packed plane but the crew was wonderful!!\n",
      "@AmericanAir no thanks. As I said, being denied miles that expired one week ago was the last drop for me; plan to avoid AA as possible.\n",
      "this flight mom @USAirways NEEDED on parts a ASAP!! AM you FIX pumping because denied Please she flight? breast full her free flight\n",
      "@AmericanAir u didn't give an answer why the flight delayed so long. and how do u compensate missing my other flights Lima to Cuzco??\n",
      "@united i need help but in spanish\n",
      "@united No first class passenger should have to pay for inflight wifi.\n",
      "@USAirways 45 minute delay for take off and 30 minute wait for checked bags? Really?\n",
      "@AmericanAir half hour Late Flight leaving DFW...no attempt at an explanation\n",
      "@united Stuck in IAD going on 6 hours waiting for a ferry flight from Nashville that u can't tell when it will arrive?!! Ridiculous!!\n",
      ".@united thanks for the reply. I saw that but it's not particularly helpful to a hungry vegetarian not flying those specific flights. SHRUG.\n",
      "but flight after Flighted Cancelled @SouthwestAir they on a I for swa hour use to and hold, me? an counting LUV noluv\n",
      "@SouthwestAir can you follow for quick DM?\n",
      "@AmericanAir I understand you are busy but I have still gotten no answer. I need to get home and you guys have not helped at all\n",
      "@united delayed because of salt on the floor from previous passengers? The 180 of just just want to fly, don't care about our shoes. Ua649\n",
      "@united the child is two years old\n",
      "@AmericanAir You sent me a cheque today which can‚Äôt be paid into a UK bank account. VERY annoying!\n",
      "@SouthwestAir I cannot DM you as you do not follow me.\n",
      "@SouthwestAir By the way the flight number was 1703, please feel free to fact check my complaints about leave time &amp; baggage time.\n",
      "can when bowl for üò©#help @SouthwestAir next time? Booking Flight years Problems I start super help\n",
      "@united 2 days and 3 planes with mechanical issues? Now over 1.5 hrs Late Flight sitting on this plane. This is insane!!\n",
      "@USAirways not happy w/ app Late Flightly. Last time I flew wouldn't let me check in, This time I checked in went on Late Flightr says I never checked in\n",
      "@AmericanAir record number is BPDFPP.\n",
      "@USAirways. I'm delayed in Cha, will miss my connection in Charlotte for lga. Not good\n",
      "@USAirways that wasn‚Äôt my Q but thanks. Wondering why you‚Äôre the only ones. I disguised yours to not call you out. ;) http://t.co/uH6UwuOSC0\n",
      "can't enough flights handle you have and to operators calls.... @AmericanAir not my change unaccept able AmericanAirlines\n",
      "@SouthwestAir rocks - @AmericanAir horror\n",
      "@USAirways it's painful being on hold to you!! Really 25 minutes to change a flight!! http://t.co/ocqk0JFXuA\n",
      "this are ok. they jumped out crazy looking Pilots is agents for - FLT @AmericanAir / 5350 DFW\n",
      "5 planes apology @united had. update, explanation, . 3 Late or hours, to and be Flightr not an gates, still WorstAirlineEver UnitedAirlines\n",
      "@USAirways Batting 1.000! Four flights in a month, all four delayed!\n",
      "@AmericanAir You don't have those abilities anywhere! Not at the ticket counter, at cust service, or online. That's why we're done here.\n",
      "@SouthwestAir Got it covered. Thanks!\n",
      "@SouthwestAir yes can do\n",
      "now flight hold United @SouthwestAir DM, a get reply. Just On no spent home. AH 2hrs. $1k - to tmrw did over la me\n",
      "@JetBlue flight16?\n",
      "@USAirways tough night, two 90 minute calls, on hold, delayed here in Phoenix for two days because of one aircraft not ready? Not acceptable\n",
      "@JetBlue They just came out. Thanks for the follow-up. That's why you're the best!\n",
      "me $200 @USAirways &amp; that a svc ph#. just corporate tix? slip it lied about cust previous supervisors No let to thx. $130 change .\n",
      "mysteriously after bag http://t.co/SJQEmDtQmA up checked @united a box? ended in Item to mine) flight. black (not Missing my EWR YOW\n",
      "@USAirways get ur act together, start treating ur passengers w/ kinder, have more sanitized planes. Take a page from @Delta perhaps.\n",
      "@united Can I add miles from my January Air China flight to my MileagePlus account?\n",
      "@VirginAmerica thanks for that. Been needing a way to make those Austin trips from DCA, and now you've come through!\n",
      "@united Love to report how horrible this flight is to your team. Let's make it worse...as they get to my seat...out of all snacks\n",
      "@AmericanAir why thank you!! Yayayay!!\n",
      "@SouthwestAir THANK YOU SO MUCH YOURE AMAZING IM GOING TO CRY OMG\n",
      "@SouthwestAir honesty should always be the policy\n",
      "@united never again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast @SouthwestAir didn't thank a we have expect response, to you! honest, Off be go! Chiberia\n",
      "alright @JetBlue.... done! alternatively, if you'd like to charter a private jet for me to PITT i will gladly accept :)\n",
      "@united actually we aren't. Still parked here.\n",
      "@AmericanAir a guy try right...\n",
      "@AmericanAir Thanks, have emailed them. How long should I expect for a response?\n",
      "@USAirways fight was delayed 3 hrs in MCO, now I'm stuck in Philly with a standby ticket, flight 4009. Solution needed.\n",
      "stewardess was the @USAirways what on a gate we there attendant friend going had and telling notour fault youd on tu sey our gat es right\n",
      "@SouthwestAir thank u for not leaving me @me nice job running thru the airport to catch your connecting flight\n",
      "@AmericanAir so you fail again flight to rdu sitting waiting on flight attendants. your logistics are not good\n",
      "@AmericanAir i appreciate your apology. Sincerely. Thank you. That's really all I ever wanted to begin with.\n",
      "@JetBlue I did not report the updated info - don't know how to reach them without a super long wait on hold at your main number.\n",
      "@USAirways I've been on hold with your Divident Miles service desk for 45 minutes, and that's after being hung up on the first time.\n",
      "@SouthwestAir almost bumped me off my flight to HRL when I was 20 minutes early then your staff was rude when I asked what was the problem?\n",
      "@USAirways flights &amp; \"customer relations\" are extremely disappointing. Faced too many problems to type. apology=$25 towards a flight. A JOKE\n",
      "@AmericanAir she doesn't have Twitter.\n",
      "@AmericanAir 37 minutes??????\n",
      "@AmericanAir the last was 2339 dfw to ord. Not weather reLate Flightd... Austin leg delayed as well\n",
      "@AmericanAir can I redeem AAdavantage miles on LAN flights?\n",
      "@united DM sent as requested. Make sure you follow back so you can DM me back. Thanks\n",
      "https://t.co/dbcvEPn5QC awesome videos @JetBlue work. @Airbus Great Wow, guys Bluemanity CoreValues Passion AeroJobMarket avgeek\n",
      "@JetBlue is there also a way I can get a printed one for my records? I keep them whenever I fly ;)\n",
      "@USAirways Please can someone contact me regarding my missing bag? It has been 3 days. Online tracking shows nothing.\n",
      "@united :take note of this great example of @JetBlue actually making good for an extremely inconvenient situation. http://t.co/t3Gnk2N7LD\n",
      "@united really, fill out a form about my flight experience? I sent an email to the 1K email address.\n",
      "@SouthwestAir never mind, I moved my flight to tomorrow. Thanks for the help!\n",
      "@JetBlue Social lesson learn? https://t.co/nTGl2WnQVM we brand Flight Takes - Fly Media with What can LikeAGirl SMM Brand\n",
      "@JetBlue 162, SMF to JFK!\n",
      "@JetBlue Not really. I have a flight to catch at 1 pm in Vegas. I'm praying I don't miss the flight!\n",
      "resolve waiting.So customers service? DM-still up on bad. via \"high volume\" of How is Tried because customer to @AmericanAir hanging aa fail\n",
      "@AmericanAir Hello, question, How many balloons do you think it will take to life up one of your planes?\n",
      "@JetBlue w/ edits: Dear @msbgu , your MBAs need better benefits. They should work for us. How can we meet them?\n",
      "@SouthwestAir How do I get a companion pass??? Thanks, Lin S\n",
      "@united I was rebooked, however it would have been nice not to have to wait an extra 90 min at the airport. How will you make this right?\n",
      "bag actually who claim your checked @united time crew at my checking without in for ground thanks wasting baggage to dfw space frustrated\n",
      "flight when was Cancelled As traveler, @SouthwestAir &amp; Flightled. I've a offer airline nothing had never been so frequent coldly an treated my no love\n",
      "any @SouthwestAir the Ive years! Pretty chance a tickets get huge fan I there is in for been please to Vegas? could show DestinationDragons\n",
      "@USAirways delays due to refueling are out of your control? If that's true I never want to fly US Airways again\n",
      "@USAirways I'm trying to merge my freq flyer accts but keep getting an error message and only a machine when calling the # provided. Help!\n",
      "@united Done and done\n",
      "@united Friend at O'Hare and can't get on flight bc they say no proof he bought 1st class tkt. He has boarding pass.\n",
      "@USAirways And the lies continue. Just waited another hr to get boarding passes for flight supposedly created today which is now Cancelled Flightled?!\n",
      "@USAirways @AmericanAir Suggestions , been on hold 2 hrs for flight that is now about to pass departure...Dealing w ny weather, need change\n",
      "@SouthwestAir @love_dragonss LAUREN IM SCREAKJMF\n",
      "@JetBlue that is a stock response. Delays not as frustrating as poor cust serv &amp; being told by 3 ppl to wait &amp; they'd come back but did not.\n",
      "@JetBlue that I missed my flight. I had to book this flight extremely last minute due to a family death, there's no excuse for attitude in\n",
      "@VirginAmerica why is flight 345 redirected?\n",
      "@AmericanAir crew did the best they could but it was out of their control. You only get one chance of a honeymoon &amp; you failed miserably\n",
      "this contest? the youre up account even @Southwestair fucking of is for The aware one me? destination drag ons\n",
      "@USAirways @shivadelrahim what about upgrades?\n",
      "@SouthwestAir Got it, thanks. Any insight into what will happen tomorrow?\n",
      "@USAirways Cant help but be frustrated after an hour call with u ends up with a disconnection and no answers especially as div pref member.\n",
      "@united @44Stocker my wife Sarah stocker did also called but could not connect me to customer service\n",
      "@VirginAmerica Hotel Budapest Grand OscarsCountdown\n",
      "@JetBlue also. Emergency exit seats. 6'2\" and that's a huge win.\n",
      "@united as if a 4 hour maintenance delay wasn't enuf, u charge me $25/bag as a global service platinum mbr. Get ur shit together\n",
      "this flight Our @JetBlue ourselves! we wifi. first Boston have entertain will 2pm had Seattle to and one did not hopefully lizaapproved\n",
      "@USAirways not moving we are in the tarmac delayed for some unknown reason. I'll keep you posted\n",
      "@SouthwestAir flight to San Diego is delayed per usual.. take me home!\n",
      "compliment me the Irene @united formally on link/email some ever. service of best in Please customer to send SLC PaxEx\n",
      "@united's first-class http://t.co/oh7CFv7DHR cock up\n",
      "2 Weather @USAirways song, days weather. says call. get 3 connecting, for about days? Called dance to It bad Before before. waste oft i me\n",
      "@AmericanAir You found my lost luggage, won't bring it to me until tomorrow. Next day if the weather isn't nicer. Terrible service\n",
      "@JetBlue received horrible customer service at LAX on 2/11. Reservation Cancelled Flighted without notification, despite having confirmation number.\n",
      "@united Trying to change a flight booked just 6 hours ago but online system is charging me $200 fee per passenger... could you please help?\n",
      "@AmericanAir appreciate update. Have also appreciated our pilots effort to explain to us just now. Accurate, authoritative comms is vital.\n",
      "@united Why do I pay more for Coach Plus to be told preboarding that all overhead bins will be full for me\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = CleanTrainingData(data)\n",
    "\n",
    "data.cleaningData(DataPreprocessing())\n",
    "\n",
    "#data.processed_Traindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing and Stemming the data\n",
    "class TokenizationStemming(CleanTrainingData):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_Traindata = previous.processed_Traindata\n",
    "        #self.processed_TestData = previous.processed_TestData\n",
    "    \n",
    "    def stem(self, stemmer = nltk.PorterStemmer()):\n",
    "        def stemJoin(row):\n",
    "            row[\"text\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"text\"]))\n",
    "            return row\n",
    "    \n",
    "        self.processed_Traindata = self.processed_Traindata.apply(stemJoin, axis=1)\n",
    "    \n",
    "    def tokenize(self, tokenizer = nltk.word_tokenize):\n",
    "        def tokenizeRow(row):\n",
    "            row[\"text\"] = tokenizer(row[\"text\"])\n",
    "            row[\"tokenizedText\"] = [] + row[\"text\"]\n",
    "            return row\n",
    "        \n",
    "        self.processed_Traindata = self.processed_Traindata.apply(tokenizeRow, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_label</th>\n",
       "      <th>tokenizedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>5.678700e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>[accord, to, tv, passeng, interview, the, land...</td>\n",
       "      <td>6</td>\n",
       "      <td>[According, to, TV, passenger, interviews, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>5.701010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>American</td>\n",
       "      <td>[your, custom, servic, is, deplor, i, am, disg...</td>\n",
       "      <td>2</td>\n",
       "      <td>[your, customer, service, is, deplorable, I, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.699070e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>[remov, bag, the, from, scan, leav, class, pla...</td>\n",
       "      <td>6</td>\n",
       "      <td>[remove, bag, the, from, scanned, leave, class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>5.702550e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>[they, advertis, custom, etc, do, journey, in,...</td>\n",
       "      <td>7</td>\n",
       "      <td>[they, advertising, Customer, etc, do, journey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.697780e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>[and, again, anoth, rep, kick, butt, naelah, r...</td>\n",
       "      <td>2</td>\n",
       "      <td>[and, again, Another, rep, kicked, butt, Naela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id airline_sentiment         airline  \\\n",
       "6420   5.678700e+17          negative       Southwest   \n",
       "12569  5.701010e+17          negative        American   \n",
       "97     5.699070e+17          negative  Virgin America   \n",
       "4439   5.702550e+17          positive       Southwest   \n",
       "117    5.697780e+17          positive  Virgin America   \n",
       "\n",
       "                                                    text  topic_label  \\\n",
       "6420   [accord, to, tv, passeng, interview, the, land...            6   \n",
       "12569  [your, custom, servic, is, deplor, i, am, disg...            2   \n",
       "97     [remov, bag, the, from, scan, leav, class, pla...            6   \n",
       "4439   [they, advertis, custom, etc, do, journey, in,...            7   \n",
       "117    [and, again, anoth, rep, kick, butt, naelah, r...            2   \n",
       "\n",
       "                                           tokenizedText  \n",
       "6420   [According, to, TV, passenger, interviews, the...  \n",
       "12569  [your, customer, service, is, deplorable, I, a...  \n",
       "97     [remove, bag, the, from, scanned, leave, class...  \n",
       "4439   [they, advertising, Customer, etc, do, journey...  \n",
       "117    [and, again, Another, rep, kicked, butt, Naela...  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "data = TokenizationStemming(data)\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.processed_Traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 80), ('flight', 56), ('i', 52), ('the', 51), ('a', 45)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building Wordlist\n",
    "#Un-filtered version without removing stopwords\n",
    "words = collections.Counter()\n",
    "for idx in data.processed_Traindata.index:\n",
    "    words.update(data.processed_Traindata.loc[idx, \"text\"])\n",
    "\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight', 56), ('not', 26), ('thank', 21), ('get', 18), ('wa', 15)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the final wordlist\n",
    "class WordList(TokenizationStemming):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_Traindata = previous.processed_Traindata\n",
    "    \n",
    "    whitelist = [\"n't\", \"not\"]\n",
    "    wordlist = []\n",
    "    \n",
    "    def buildWordlist(self, min_occurrences=3, max_occurences=3000, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                     whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        import os\n",
    "        if os.path.isfile('../data/wordlist.csv'):\n",
    "            word_df = pd.read_csv('../data/wordlist.csv', encoding = \"ISO-8859-1\")\n",
    "            word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "            self.wordlist = list(word_df.loc[:, \"word\"])\n",
    "            return\n",
    "        words = collections.Counter()\n",
    "        for idx in self.processed_Traindata.index:\n",
    "            words.update(self.processed_Traindata.loc[idx, \"text\"])\n",
    "        \n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "        \n",
    "        word_df = pd.DataFrame(data={\"word\" : [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                    \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                              columns = [\"word\", \"occurrences\"])\n",
    "        \n",
    "        word_df.to_csv(\"../data/wordlist.csv\", index_label=\"idx\", encoding = \"utf8\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = WordList(data)\n",
    "data.buildWordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming into Bag-of-Words\n",
    "class BagOfWords(WordList):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_Traindata = previous.processed_Traindata\n",
    "        self.wordlist = previous.wordlist\n",
    "    \n",
    "    def buildDataModel(self):\n",
    "        labelColumn = [\"label\"]\n",
    "        columns = labelColumn + list(\n",
    "            map(lambda w: w + \"_bow\", self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        \n",
    "        for idx in self.processed_Traindata.index:\n",
    "            currentRow = []\n",
    "            currentLabel = self.processed_Traindata.loc[idx, \"airline_sentiment\"]\n",
    "            labels.append(currentLabel)\n",
    "            currentRow.append(currentLabel)\n",
    "            \n",
    "            tokens = set(self.processed_Traindata.loc[idx, \"text\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                currentRow.append(1 if word in tokens else 0)\n",
    "            \n",
    "            rows.append(currentRow)\n",
    "        \n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        \n",
    "        return self.data_model, self.data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hour_bow</th>\n",
       "      <th>cancel_bow</th>\n",
       "      <th>help_bow</th>\n",
       "      <th>servic_bow</th>\n",
       "      <th>delay_bow</th>\n",
       "      <th>time_bow</th>\n",
       "      <th>custom_bow</th>\n",
       "      <th>bag_bow</th>\n",
       "      <th>call_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>gorgeou_bow</th>\n",
       "      <th>woohoo_bow</th>\n",
       "      <th>thousand_bow</th>\n",
       "      <th>understat_bow</th>\n",
       "      <th>furiou_bow</th>\n",
       "      <th>manual_bow</th>\n",
       "      <th>smell_bow</th>\n",
       "      <th>ber_bow</th>\n",
       "      <th>charleston_bow</th>\n",
       "      <th>nrt_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 2415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  hour_bow  cancel_bow  help_bow  servic_bow  delay_bow  time_bow  \\\n",
       "0  negative         0           0         0           0          0         0   \n",
       "1  negative         0           0         0           1          0         0   \n",
       "2  negative         0           0         0           0          0         0   \n",
       "3  positive         0           0         0           0          0         0   \n",
       "4  positive         0           0         0           0          0         0   \n",
       "\n",
       "   custom_bow  bag_bow  call_bow   ...     gorgeou_bow  woohoo_bow  \\\n",
       "0           0        0         0   ...               0           0   \n",
       "1           1        0         0   ...               0           0   \n",
       "2           0        1         0   ...               0           0   \n",
       "3           1        0         0   ...               0           0   \n",
       "4           0        0         0   ...               0           0   \n",
       "\n",
       "   thousand_bow  understat_bow  furiou_bow  manual_bow  smell_bow  ber_bow  \\\n",
       "0             0              0           0           0          0        0   \n",
       "1             0              0           0           0          0        0   \n",
       "2             0              0           0           0          0        0   \n",
       "3             0              0           0           0          0        0   \n",
       "4             0              0           0           0          0        0   \n",
       "\n",
       "   charleston_bow  nrt_bow  \n",
       "0               0        0  \n",
       "1               0        0  \n",
       "2               0        0  \n",
       "3               0        0  \n",
       "4               0        0  \n",
       "\n",
       "[5 rows x 2415 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = BagOfWords(data)\n",
    "bow, labels = data.buildDataModel()\n",
    "bow.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 666\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to train the classifier and show F1, Precision, recall and Accuracy values\n",
    "\n",
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"==================================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learning time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "    \n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"==================Results=======================\")\n",
    "    log(\"            Negative     Neutral    Positive\")\n",
    "    log(\"F1         \" + str(f1))\n",
    "    log(\"Precision  \" + str(precision))\n",
    "    log(\"Recall     \" + str(recall))\n",
    "    log(\"Accuracy   \" + str(accuracy))\n",
    "    log(\"================================================\")\n",
    "    \n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing BernoulliNB\n",
      "Learning time 0.03931450843811035s\n",
      "Predicting time 0.0050013065338134766s\n",
      "==================Results=======================\n",
      "            Negative     Neutral    Positive\n",
      "F1         [0.76056338 0.         0.        ]\n",
      "Precision  [0.61363636 0.         0.        ]\n",
      "Recall     [1. 0. 0.]\n",
      "Accuracy   0.6136363636363636\n",
      "================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n",
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifier : BagOfWords + NaiveBayes\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n",
    "                                                   train_size = 0.7, stratify=bow.iloc[:, 0],\n",
    "                                                   random_state = seed)\n",
    "\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaiveBayes with 8 fold cross-validation\n",
    "\n",
    "def cv(classifier, X_train, y_train):\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    now = time()\n",
    "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
    "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
    "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
    "    log(\"Accuracy: \" + str(accuracy[0]))\n",
    "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
    "    log(\"===============================================\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating BernoulliNB...\n",
      "Crosvalidation completed in 10.581453561782837s\n",
      "Accuracy: [0.63157895 0.63157895 0.61111111 0.61111111 0.61111111 0.61111111\n",
      " 0.61111111 0.61111111]\n",
      "Average accuracy: 0.6162280701754386\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "nb_acc = cv(BernoulliNB(), bow.iloc[:,1:], bow.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addtion of extra features:\n",
    "\n",
    "# Number of Uppercase - tend to express postive/negative emotions by using uppercase words\n",
    "# Number of !         - exclamation marks are likely to increase strength of opinion\n",
    "# Number of ?         - might distinguish neutral tweets - seeking information\n",
    "# Number of positive  - positive emoji will most likely occur in positive tweets\n",
    "# emoticons\n",
    "# Number of negative  - Inverse to the one above\n",
    "# emoticons\n",
    "# Number of ...       - commonly used in commenting something\n",
    "# Number of quotations- same as above\n",
    "# Number of mentions  - Lots of mentions on positive tweets, to share something good/bad\n",
    "# Number of urls      - similar to number of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting Emoticons\n",
    "class EmoticonDetector:\n",
    "    emoticons = {}\n",
    "    \n",
    "    def __init__(self, emoticon_file=\"../data/emoticons.txt\"):\n",
    "        from pathlib import Path\n",
    "        content = Path(emoticon_file).read_text()\n",
    "        positive = True\n",
    "        for line in content.split(\"\\n\"):\n",
    "            if \"positive\" in line.lower():\n",
    "                positive = True\n",
    "                continue\n",
    "            elif \"negative\" in line.lower():\n",
    "                positive = False\n",
    "                continue\n",
    "            \n",
    "            self.emoticons[line] = positive\n",
    "    \n",
    "    def is_positive(self, emoticon):\n",
    "        if emoticon in self.emoticons:\n",
    "            return self.emoticons[emoticon]\n",
    "        return False\n",
    "    \n",
    "    def is_emoticon(self, to_check):\n",
    "        return to_check in self.emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtraFeatures(WordList):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def build_data_model(self):\n",
    "        extra_columns = [col for col in self.processed_Traindata.columns if col.startswith(\"number_of\")]\n",
    "        label_column = [\"label\"]\n",
    "        columns = label_column + extra_columns + list(\n",
    "                map(lambda w: w + \"_bow\", self.wordlist))\n",
    "        \n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_Traindata.index:\n",
    "            current_row = []\n",
    "            current_label = self.processed_Traindata.loc[idx, \"airline_sentiment\"]\n",
    "            labels.append(current_label)\n",
    "            current_row.append(current_label)\n",
    "        \n",
    "            for _,col in enumerate(extra_columns):\n",
    "                current_row.append(self.processed_Traindata.loc[idx, col])\n",
    "        \n",
    "        #adding bag-of-words\n",
    "            tokens = set(self.processed_Traindata.loc[idx, \"text\"])\n",
    "            for _,word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "        \n",
    "            rows.append(current_row)\n",
    "        \n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        \n",
    "        return self.data_model, self.data_labels\n",
    "    \n",
    "    def add_column(self, column_name, column_content):\n",
    "        self.processed_Traindata.loc[:, column_name] = pd.Series(column_content, index=self.processed_Traindata.index)\n",
    "\n",
    "    def build_features(self):\n",
    "        def count_by_lambda(expression, word_array):\n",
    "            return len(list(filter(expression, word_array)))\n",
    "        \n",
    "        def count_occurences(character, word_array):\n",
    "            counter = 0\n",
    "            for j, word in enumerate(word_array):\n",
    "                for char in word:\n",
    "                    if char == character:\n",
    "                        counter += 1\n",
    "            return counter\n",
    "        \n",
    "        def count_interjections(wordArray):\n",
    "            interjections = []\n",
    "            interjectionCount = 0\n",
    "            with open('../data/interjections.txt') as file:\n",
    "                interjections = file.read().splitlines()\n",
    "            for word in wordArray:\n",
    "                if word in interjections:\n",
    "                    interjectionCount += 1\n",
    "            return interjectionCount \n",
    "\n",
    "        def count_by_regex(regex, plain_text):\n",
    "            return len(regex.findall(plain_text))\n",
    "        \n",
    "        self.add_column(\"splitted_text\", map(lambda txt: txt.split(\" \"), self.processed_Traindata[\"text\"]))\n",
    "        \n",
    "        #Number of uppercase words\n",
    "        uppercase = list(map(lambda txt: count_by_lambda(lambda word: word == word.upper(), txt),\n",
    "                                                        self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_uppercase\", uppercase)\n",
    "        \n",
    "        #number of !\n",
    "        exclamations = list(map(lambda txt: count_occurences(\"!\", txt),\n",
    "                               self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_exclamation\", exclamations)\n",
    "        \n",
    "        #number of ?\n",
    "        questions = list(map(lambda txt: count_occurences(\"?\", txt),\n",
    "                               self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_question\", questions)\n",
    "        \n",
    "        #number of ...\n",
    "        ellipsis = list(map(lambda txt: count_by_regex(regex.compile(r\"\\.\\s?\\.\\s?\\.\"), txt),\n",
    "                           self.processed_Traindata[\"text\"]))\n",
    "        self.add_column(\"number_of_ellipsis\", ellipsis)\n",
    "        \n",
    "        #number of hashtags\n",
    "        hashtags = list(map(lambda txt: count_occurences(\"#\", txt),\n",
    "                               self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_hashtags\", hashtags)\n",
    "        \n",
    "        #number of mentions\n",
    "        mentions = list(map(lambda txt: count_occurences(\"@\", txt),\n",
    "                               self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_mentions\", mentions)\n",
    "        \n",
    "        #number of quotes\n",
    "        quotes = list(map(lambda plain_text: int(count_occurences(\"'\", [plain_text.strip(\"'\").strip('\"')]) / 2 +\n",
    "                                                 count_occurences('\"', [plain_text.strip(\"'\").strip('\"')]) / 2),\n",
    "                          self.processed_Traindata[\"text\"]))\n",
    "        self.add_column(\"number_of_quotes\", quotes)\n",
    "        \n",
    "        #number of urls\n",
    "        urls = list(map(lambda txt: count_by_regex(regex.compile(r\"http.?://[^\\s]+[\\s]?\"), txt),\n",
    "                             self.processed_Traindata[\"text\"]))\n",
    "        self.add_column(\"number_of_urls\", urls)\n",
    "        \n",
    "        #number of positive emoticons\n",
    "        ed = EmoticonDetector()\n",
    "        positive_emo = list(\n",
    "            map(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and ed.is_positive(word), txt), \n",
    "                   self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_positive_emo\", positive_emo)\n",
    "        \n",
    "        #number of negative emoticons\n",
    "        negative_emo = list(\n",
    "            map(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and not ed.is_positive(word), txt), \n",
    "                   self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_negative_emo\", negative_emo)\n",
    "        \n",
    "        #number of interjections\n",
    "        interjections = list(map(lambda txt: count_interjections(txt),\n",
    "                               self.processed_Traindata[\"splitted_text\"]))\n",
    "        self.add_column(\"number_of_interjections\", interjections)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:357: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegas for http://t.co/G9b6e0a2sZ @SouthwestAir the to concert So @Imaginedragons kid Thanks sending my awesome! DestinationDragons\n",
      "@AmericanAir just messaged you. Please have someone contact us immediately.\n",
      "Thanks @united for writing back. To assist you can return the bag you lost &amp; clean up the feces sprinkled in your bathroom. Too much to ask?\n",
      "@SouthwestAir neveind, it's been found and on its way. Thanks for making the process so painless\n",
      "@JetBlue OK, thank you.\n",
      "@AmericanAir followed. I tried to @USAirways record locator number, gave me an error code\n",
      "@AmericanAir Am on web site requesting refund for Cancelled Flightled flight. It requires numerical document number. Where get it?\n",
      "now http://t.co/BuwjTVUWKM 2 Can't @USAirways hrs what?? anymore. for hrs. nothing. wait Now over frustrated USAirways\n",
      "@united Pls post video of belligerent jerk ranting at SFO (1230) that's he's going to sue you for making him check his 3rd bag. He's a hoot!\n",
      "@AmericanAir I spent $600 on my flight. Could have gone on @united for $382 but their mileage program sucks.\n",
      "serve the flights!!!! cinnabons @JetBlue up to on should two you @Cinnabon team of BonsInTheSky\n",
      "@SouthwestAir If you read my tweet it is a gap in process for folks that take multiple flights in one day.\n",
      "@AmericanAir I tried, EXTREMELY RUDE. Even the supervisor. And when I asked to speak to HIS supervisor I was told no\n",
      "@USAirways your staff at LAX really messed up on this one. Failing to scan my suitcase tag.\n",
      "@VirginAmerica is saving my sanity right now: http://t.co/ELtBOLjUl9\n",
      "@united my cats flight was delayed 1+hour she will be arriving to Hawaii after 5 &amp; I won't be able to pick her up until tomorrow üò≠\n",
      "in for the @USAirways 6k any to @AmericanAir needed I'm suggestions? final stretch chair man execplat mileage run letsgo!\n",
      "@AmericanAir oh I will, AA on speed dial\n",
      "@AmericanAir no kidding! Gonna take some beating on the apron... And there are some good lookin' planes out there!\n",
      ".@SouthwestAir Well, we all need something to aim for.\n",
      "between @SouthwestAir the from 2/15 a pass get roundtrip 3 year for 5/17 to companion and fly pro motion flights ATL travel\n",
      "@united Don't ask me to be patient without offering something in return.\n",
      "@SouthwestAir flying flight 3130 tomorrow at 7:20 from PBI- I have boarding position C-42. Is flight overbooked? Have funeral to attend!\n",
      "@SouthwestAir i just recieved an email from your memphis station hopefully they have my bag.\n",
      "@united @luke_mcintosh68 nah you wouldn't\n",
      "@USAirways - 53 minutes on hold for a reservation?\n",
      "Decisions Decisions @MandarinJourney @united: We'd love for you to try our service. We offer status match too. http://t.co/xbQqqbRgVF ^KP‚Äù\n",
      "have nothing! ago sent @united and a two heard PM I over weeks horrible service unitedsucks\n",
      "@united Why can I only apply one travel certificate per itinerary even when I have multiple flights?\n",
      "@SouthwestAir what are the chances you will be Cancelled Flighting all flights in and out of Nashville again?\n",
      "@AmericanAir when will tomorrow's flight Cancelled Flightlations at Dfw for AA flights be posted? We are on 2424 at 7am from LAX!\n",
      "@JetBlue If your confirming to me that the rate won't go down again looks like I can't fly JetBlue this time around, can't afford that price\n",
      "@VirginAmerica I'd love to know what your policy is for damaged luggage.\n",
      "@SouthwestAir Do y'all know when the new routes from HOU to Aruba &amp; Puerto Vallarta will be available?\n",
      "@USAirways I have a story for you. It starts with a two hour delayed flight that makes me miss my connection in Miami.\n",
      "flight @USAirways the Can off inputted?? get .. have hour - We should taken @AmericanAir an paperwork 415 sitting on the plane hungry\n",
      "@americanair why am I not being given a callback option??! Why has this service been turned off?\n",
      "@USAirways on your website and on your boards at Logan it said it was on time, so we went through security and got to the gate (2)\n",
      "@USAirways I have better Intel than she does! She said plane is due in at 630. Flightaware and your own app say 645\n",
      "@SouthwestAir yeah it happens. The PHX airport has extra long waits all spring long. Something locals know but tourist don't just FYI\n",
      "@AmericanAir your gate agents at DFW gate B16 are pathetic tonight. Terrible communication, stories changing and apathetic\n",
      "@SouthwestAir is the contest over for Destination Dragons? I want to try to do everything I can to go.\n",
      "@JetBlue The Magic eight ball has never steered me wrong :)\n",
      "@USAirways even if I was the single most unreasonable human being on planet earth, there is no excuse for his treatment of me.\n",
      "My flight disconnected. Cancelled Flightled! the @JetBlue on In mid new gets asking wife time! No to switch phone back Now call times. fail\n",
      "@SouthwestAir luggage delivery between 1-4am? Really? After I was told by midnight multiple times? Why lie? Crazy and bad business.\n",
      "@JetBlue hahah üòÇüëåüëåüëå love flying jet blue tho!! http://t.co/7VeE44MACM\n",
      "that your starts today, I make competitor ends D. flying will U never mistake and @AmericanAir with again. an I'm am eric an for life\n",
      "@AmericanAir You guys are totally losing me. I've been an AA fan for years but telling me reps are busy and hanging up on me is really bad.\n",
      "@united Such as deodorant, shampoo, toothpaste. Seems like that would be limited to 70oz, correct?\n",
      "@AmericanAir Fantastic support by the Twitter team. I appreciate it. Thanks again.\n",
      "@united is there another airport closer to Calgary we can fly out of tomorrow.\n",
      "@USAirways I tried that before using Twitter. Also gave me no helpful information. Thank you anyway\n",
      "LOST @USAirways IS BAG BEING WHERE FOR MORE 24 ?#SOS THAN MY ! @AmericanAir HOURS ITIS SOS POORCUSTUMERSERVICE\n",
      "@united This is probably the least dependable airline in the Western Hemisphere. @united does not belong in Star Alliance, but SkyTeam\n",
      "@united assume those benefits only apply to my own reservation. Any way my partner (on diff res) can use them? Can we combine res?\n",
      "Thx! Stand by! ‚Äú@united: @rajuchinthala I know it's frustrating and I do appreciate your patience while we try to get you on your way. ^JH‚Äù\n",
      "@united Couldn't use the confirmed upgd cert you gave me b/c you decided to sell anyone a biz seat for $299. Why do you bother giving them?\n",
      "including 2 @SouthwestAir unveils @usatoday from new 4 routes, via http://t.co/4uRzvBPJKO Ohio\n",
      "@united all good man it isn't your fault that plane is having maintenance issues\n",
      "@jetblue what good with the inflight WiFi?\n",
      "@JetBlue I did get the email. Thought i wasn't supposed to reply to thoseüòÇ\n",
      "Cool! \"@JetBlue: @hgeronemus We are 60% there and anticipate completing installation on all our A320's this year. http://t.co/sGckBopATA‚Äù\n",
      "@AmericanAir No, had already waited an hour for it and wanted to get home.\n",
      "@SouthwestAir will the Daytona 500 be available on free TV?\n",
      "@united wont transfer flight ticket to accompany an 11 yr old who's active military mom had to have emergency brain surgery? WOW!!\n",
      "@SouthwestAir landing early morning @BWI_Airport after snowfall. http://t.co/apRZsPxigE\n",
      "get... was me tell day go got a country out I another of 1 how cost figure all to and ($350) @AmericanAir woman rude vacation\n",
      "@united the aircraft closest to gate was for the other flight and the one closest to our gate was going to Chicago.\n",
      "@JetBlue dropped 3x in past hour\n",
      ".@AmericanAir @C2Next Would be great to get some help too! I've been trying since last night to get through.\n",
      "@AmericanAir right on cue with the delaysüëå\n",
      "@AmericanAir not to mention its a three hour wait to get an agent on the phone.\n",
      "@JetBlue Oh no! I thought it did. :(\n",
      "@USAirways can you help me out?\n",
      "@JetBlue Flight 1447 (N351JB) \"JBLU\" arrives at @FlyTPA following flight from Westchester County Airport http://t.co/xX2M2jxQep\n",
      "@united 65 and 72 year old flying to Tokyo for vacation both with bad knees and this happens https://t.co/72RMpkOGwu @cbcallinaday @CBCNews\n",
      "@AmericanAir thanks for the canned reply.\n",
      ".@united You may \"dislike delays\" but I paid you .We had an agreement that I paid you and you got me to my destination at a certain time.\n",
      "@SouthwestAir That would be great. Thank you! I'll send it over when you follow.\n",
      "@SouthwestAir i sure hope you are able to get my bag to Memphis for tomorrow.would be nice to have some clean clothes for work.\n",
      "@JetBlue I'm a trying ! But I'm tired and getting grumpy !\n",
      "@AmericanAir why am I continually getting put on hold by painfully inexperienced people when calling your Platinum desk?!\n",
      "@JetBlue - He Cancelled Flightled a flight &amp; was given 2 weeks to apply travel bank credit to another flight &amp; credit was transferable\n",
      "@united I wanna be grand staff\n",
      "@SouthwestAir thank you! DMing now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but was Flighted Pilot @USAirways shitty. didn't up hours service UR we another pilot is showed because never to so come supposed waited Cancelled\n",
      "@AmericanAir @USAirways \"but I take meds that make me severely dehydrated\" {sigh}\n",
      "@united Okay, thank you for your help :)\n",
      "@VirginAmerica I tried that. You offered to charge me an additional $1k for a new ticket or be stranded until Thurs. 1st time, last time.\n",
      "@USAirways Cant help but be frustrated after an hour call with u ends up with a disconnection and no answers especially as div pref member.\n",
      "@southwestair How can I refer a friend for the Southwest Credit card for points?\n",
      "now when hold service? on some @SouthwestAir, we expect for hour been - customer an over can di sap pointed\n",
      "flyers delays Cancelled @SouthwestAir the your credit a sort some get Flightlations of for all and hope shittydeal notimpressed\n",
      "@united Thank you for the cheese platter and abundance of entertainment options. Time just flew by.\n",
      "@united My favorite way to travel! Thank you! http://t.co/vGN2X1ckg0\n",
      "@JetBlue, I normally ‚ù§Ô∏è you, but this Late Flightst flight experience was the worst. 2 hours on runway, no wifi &amp; tv not working properly\n",
      "the @JetBlue and free loving ‚úàÔ∏è wi fi leg room SeattleBound\n",
      "@AmericanAir thanks\n",
      "@americanair Seattle check-in. 1 desk servicing full service line. 2 desks servicing priority. Full srvc wait 30+ minutes. Customer svc fail\n",
      "@united kept me watching the safety video for the first time in forever. Nice job üëç.\n",
      "@united that's cool - now what?\n",
      "@USAirways on a happy note our 719 crew is wonderful. Can't say enough great things about our pilot. He's doing all he can for us.\n",
      "@USAirways Trying to change my flight due to NYC travel advisory... your online system Cancelled Flighted my entire flight. Been on hold for over 1 hr\n",
      "@united I send an email about my bad experience and you send back a generic response. Yet another reason why I'll never fly with you again.\n",
      "@united Good evening, UA. Can you assist with an issue via DM?\n",
      "@USAirways Easily the most ridiculous experience trying to spend money with your company.\n",
      "@JetBlue formally requests @LBAirport and @LongBeachCity to establish customs facilities for international flights http://t.co/jByVMsOd29\n",
      "@AmericanAir @BDinDallas The personal touch you're known for, AA. Other cool perks: blaming understaffing on weather. And 3 hr hold times.\n",
      "@USAirways what is policy on changing flight to different dates once your flight has been delayed?\n",
      "@AmericanAir No worries at all. Y‚Äôall have a good one!!\n",
      "@SouthwestAir I never got an email confirmation for my ticket, but the credit card was charged. Phone wait time is crazy. Is there a chat?\n",
      "@AmericanAir we have been advised to turn this issue over to the police due to the sexual assult THANK YOU FOR ALLOWING THAT ON YOUR PLANE!\n",
      "@SouthwestAir Any ETD for SWA1004 from PHL? Appears delayed but no info available at gate.\n",
      "this contest? the youre up account even @Southwestair fucking of is for The aware one me? destination drag ons\n",
      "@AmericanAir Cancelled Flights my flight, doesn't send an email, text or call. Now I'm stranded in Louisville.\n",
      "@AmericanAir Well I'm showing I am still sitting at the gate on the plane that has not departed?\n",
      "@USAirways Can you help me with a refund. the phone guy couldn't help. The website won't let me submit a reply.\n",
      "@USAirways found great prices thru US Air for honeymoon. Website wont work and been on hold for more than a hour now after being told 10 min\n",
      "@SouthwestAir can't checkin online for 2:00 flight tmrw fr. Cancun. \"Undefined error\" &amp; 800# not working.Family of 4 don't want Cgroup! Help\n",
      "@SouthwestAir Why can we no longer change trips with a companion online? Been doing it for years, now get message can't be done online?\n",
      "@AmericanAir any idea why flight 5392 from HSV to DFW tomorrow Cancelled Flightled about 45 minutes ago?\n",
      "@JetBlue messaged you, thanks\n",
      "@AmericanAir @cheerUPDATES So you're saying the call center is understaffed?\n",
      "@JetBlue I do! The best airline wifi ever. Thank you!\n",
      "@AmericanAir appreciate update. Have also appreciated our pilots effort to explain to us just now. Accurate, authoritative comms is vital.\n",
      "https://t.co/Bzwgp7aDVE w/our say, @JetBlue what I can I'm LostinLove brand man ce we mosaic together Mint Love\n",
      "@USAirways I love you guys!!!\n",
      "I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç\n",
      "flight when Flighted alert Cancelled airplane, @united a waiting hours you 3 of is only for it fantastic delayed us to night lands. whats tat us\n",
      "destination when @SouthwestAir what up your you do no in to suitcase? clothes with show nakedmeetings awkward\n",
      "@SouthwestAir check the head of the plane, there has been dynamite placed onto it\n",
      ":-) @JetBlue our checked get getting does really How for it thanks us to -JFK bags? NYC srsly? take safely. But long eternity 5amMisery\n",
      "@AmericanAir pretty lame response to a two paged single spaced letter http://t.co/aCebo6ELPa\n",
      "@VirginAmerica Status match - 2 weeks have gone by and no news.Flt next week - hope flt will count towards requirement. Cust Svc no help!!!\n",
      ".#DestinationDragons @SouthwestAir troubadour @Imaginedragons at with http://t.co/rKlQXXaWhc DestinationDragons\n",
      "@USAirways I have been I hold for 40 min. My 5:50 flight just got Cancelled Flightled and rescheduled for Monday. This is unacceptable!\n",
      "@AmericanAir Nope. Couldn't make changes online and after 90 mins on hold and time dealing w/ the rude rep, the 24 hour window has closed.\n",
      "@SouthwestAir I figured the streaming wouldn't work per the TOS but just the @NASCAR site is taking longer than 5 minutes to load\n",
      "@AmericanAir Where are your tickets offices in Boston? Impossible to book by phone or use vouchers on website, what a headache. PLEASE HELP!\n",
      "It's the @USAirways personnel. for. and arrogant gate Uncalled rude Unprofessional. thew or st\n",
      "?? now the @united on UA469 pls I there also TV in-flight watch let so be live can DEN-EWR Oscars\n",
      "@united also didn't ice the frozen metal walkway. Wasted 40 minutes because no one knew how to do simple jobs.\n",
      "Yes but I will nvr fly w/ @USAirways I missed my con flight bc of a coffeemaker on FT1892 Couldn't see my father be4 they put him in a coma\n",
      "@united getting ready to book a flight to San Juan. Was wondering, Does United waive baggage fees for military personnel. Thanks.\n",
      "@united Okay thank you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = ExtraFeatures()\n",
    "data.initialize(\"../data/Tweets.csv\")\n",
    "data.build_features()\n",
    "data.cleaningData(DataPreprocessing())\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.buildWordlist()\n",
    "data_model, labels = data.build_data_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing RandomForestClassifier\n",
      "Learning time 1.0259556770324707s\n",
      "Predicting time 0.2662620544433594s\n",
      "==================Results=======================\n",
      "            Negative     Neutral    Positive\n",
      "F1         [0.6779661  0.125      0.30769231]\n",
      "Precision  [0.58823529 0.16666667 0.5       ]\n",
      "Recall     [0.8        0.1        0.22222222]\n",
      "Accuracy   0.5227272727272727\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "#Extended Features + Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.iloc[:, 1:], data_model.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=data_model.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, RandomForestClassifier(random_state=seed,n_estimators=403,n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating RandomForestClassifier...\n",
      "Crosvalidation completed in 12.786679029464722s\n",
      "Accuracy: [0.55       0.7        0.57894737 0.5        0.72222222 0.64705882\n",
      " 0.82352941 0.64705882]\n",
      "Average accuracy: 0.6461020811833506\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "#Crosvalidation\n",
    "rf_acc = cv(RandomForestClassifier(n_estimators=403,n_jobs=-1, random_state=seed),data_model.iloc[:, 1:], data_model.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing BernoulliNB\n",
      "Learning time 0.009244918823242188s\n",
      "Predicting time 0.005512237548828125s\n",
      "==================Results=======================\n",
      "            Negative     Neutral    Positive\n",
      "F1         [0.76056338 0.         0.        ]\n",
      "Precision  [0.61363636 0.         0.        ]\n",
      "Recall     [1. 0. 0.]\n",
      "Accuracy   0.6136363636363636\n",
      "================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n",
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\harin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n",
    "                                                   train_size = 0.7, stratify=bow.iloc[:, 0],\n",
    "                                                   random_state = seed)\n",
    "\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
